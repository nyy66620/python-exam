import numpy as np
import pandas as pd
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt

# 1. åŠ è½½Diabetesæ•°æ®é›†
diabetes = load_diabetes()
X = diabetes.data
y = diabetes.target

print("æ•°æ®é›†å½¢çŠ¶:", X.shape)
print("ç‰¹å¾åç§°:", diabetes.feature_names)
print("ç›®æ ‡å˜é‡èŒƒå›´: [{:.2f}, {:.2f}]".format(y.min(), y.max()))

# 2. é€‰æ‹©å•ä¸€ç‰¹å¾bmiä½œä¸ºè¾“å…¥å˜é‡ï¼ˆbmiæ˜¯ç¬¬2ä¸ªç‰¹å¾ï¼Œç´¢å¼•ä¸º2ï¼‰
bmi_index = 2  # bmiç‰¹å¾çš„ç´¢å¼•
X_bmi = X[:, bmi_index].reshape(-1, 1)  # é€‰æ‹©bmiç‰¹å¾å¹¶é‡å¡‘ä¸ºäºŒç»´æ•°ç»„

print(f"\né€‰æ‹©çš„ç‰¹å¾: {diabetes.feature_names[bmi_index]}")
print(f"bmiç‰¹å¾ç»Ÿè®¡: å‡å€¼={X_bmi.mean():.3f}, æ ‡å‡†å·®={X_bmi.std():.3f}")

# 3. å°†æ•°æ®é›†æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆ7:3ï¼Œéšæœºç§å­å›ºå®šä¸º42ï¼‰
X_train, X_test, y_train, y_test = train_test_split(
    X_bmi, y, test_size=0.3, random_state=42
)

print(f"\nè®­ç»ƒé›†å¤§å°: {X_train.shape}")
print(f"æµ‹è¯•é›†å¤§å°: {X_test.shape}")

# 4. ä½¿ç”¨ä¸åŒé˜¶æ•°çš„å¤šé¡¹å¼ç‰¹å¾è¿›è¡Œå®éªŒ
degrees = [1, 2, 3, 4, 5]
results = []

print("\n" + "=" * 60)
print("å¤šé¡¹å¼å›å½’æ¨¡å‹ç»“æœæ¯”è¾ƒ")
print("=" * 60)

# å­˜å‚¨æ¯ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœç”¨äºå¯è§†åŒ–
predictions = {}

for degree in degrees:
    # ç”Ÿæˆå¤šé¡¹å¼ç‰¹å¾
    poly = PolynomialFeatures(degree=degree, include_bias=False)
    X_train_poly = poly.fit_transform(X_train)
    X_test_poly = poly.transform(X_test)

    # è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹
    model = LinearRegression()
    model.fit(X_train_poly, y_train)

    # åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹
    y_pred = model.predict(X_test_poly)
    predictions[degree] = y_pred

    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)

    # å­˜å‚¨ç»“æœ
    results.append({
        'é˜¶æ•°': degree,
        'RÂ²åˆ†æ•°': r2,
        'å‡æ–¹è¯¯å·®MSE': mse,
        'ç‰¹å¾æ•°é‡': X_train_poly.shape[1]
    })

    print(f"é˜¶æ•° {degree}: RÂ² = {r2:.4f}, MSE = {mse:.4f}, ç‰¹å¾æ•° = {X_train_poly.shape[1]}")

# 5. è¾“å‡ºç»“æœè¡¨æ ¼å¹¶ç¡®å®šæœ€ä½³æ¨¡å‹
results_df = pd.DataFrame(results)
print("\n" + "=" * 60)
print("ç»“æœæ±‡æ€»è¡¨æ ¼")
print("=" * 60)
print(results_df.to_string(index=False))

# ç¡®å®šæœ€ä½³æ¨¡å‹ï¼ˆRÂ²æœ€é«˜æˆ–MSEæœ€ä½ï¼‰
best_by_r2 = results_df.loc[results_df['RÂ²åˆ†æ•°'].idxmax()]
best_by_mse = results_df.loc[results_df['å‡æ–¹è¯¯å·®MSE'].idxmin()]

print("\n" + "=" * 60)
print("æ¨¡å‹æ€§èƒ½åˆ†æ")
print("=" * 60)
print(f"åŸºäºRÂ²åˆ†æ•°çš„æœ€ä½³æ¨¡å‹: é˜¶æ•° {best_by_r2['é˜¶æ•°']} (RÂ² = {best_by_r2['RÂ²åˆ†æ•°']:.4f})")
print(f"åŸºäºMSEçš„æœ€ä½³æ¨¡å‹: é˜¶æ•° {best_by_mse['é˜¶æ•°']} (MSE = {best_by_mse['å‡æ–¹è¯¯å·®MSE']:.4f})")

# æ˜ç¡®è¯´æ˜å“ªä¸ªé˜¶æ•°çš„æ¨¡å‹è¡¨ç°æœ€å‡†ç¡®
if best_by_r2['é˜¶æ•°'] == best_by_mse['é˜¶æ•°']:
    best_degree = best_by_r2['é˜¶æ•°']
    print(f"\nğŸ¯ æœ€å‡†ç¡®çš„æ¨¡å‹: é˜¶æ•° {best_degree}")
    print(f"   - RÂ²åˆ†æ•°: {best_by_r2['RÂ²åˆ†æ•°']:.4f}")
    print(f"   - å‡æ–¹è¯¯å·®MSE: {best_by_mse['å‡æ–¹è¯¯å·®MSE']:.4f}")
else:
    # å¦‚æœRÂ²å’ŒMSEé€‰æ‹©çš„ä¸ä¸€è‡´ï¼Œä¼˜å…ˆè€ƒè™‘RÂ²
    best_degree = best_by_r2['é˜¶æ•°']
    print(f"\nğŸ¯ æœ€å‡†ç¡®çš„æ¨¡å‹: é˜¶æ•° {best_degree} (åŸºäºRÂ²åˆ†æ•°)")
    print(f"   - RÂ²åˆ†æ•°: {best_by_r2['RÂ²åˆ†æ•°']:.4f}")
    print(f"   - å‡æ–¹è¯¯å·®MSE: {results_df[results_df['é˜¶æ•°'] == best_degree]['å‡æ–¹è¯¯å·®MSE'].values[0]:.4f}")

# 6. å¯è§†åŒ–ç»“æœ
plt.figure(figsize=(15, 10))

# å­å›¾1: ä¸åŒé˜¶æ•°æ¨¡å‹çš„æ‹Ÿåˆæ›²çº¿
plt.subplot(2, 2, 1)
# ç”Ÿæˆç”¨äºç»˜åˆ¶å¹³æ»‘æ›²çº¿çš„ç‚¹
x_range = np.linspace(X_bmi.min(), X_bmi.max(), 100).reshape(-1, 1)
plt.scatter(X_test, y_test, alpha=0.6, label='æµ‹è¯•æ•°æ®', color='lightgray')

for degree in degrees:
    poly = PolynomialFeatures(degree=degree, include_bias=False)
    x_range_poly = poly.fit_transform(x_range)

    # è®­ç»ƒå®Œæ•´æ•°æ®çš„æ¨¡å‹ç”¨äºç»˜åˆ¶æ›²çº¿
    model_plot = LinearRegression()
    X_bmi_poly = poly.fit_transform(X_bmi)
    model_plot.fit(X_bmi_poly, y)
    y_range_pred = model_plot.predict(x_range_poly)

    plt.plot(x_range, y_range_pred, label=f'é˜¶æ•° {degree}', linewidth=2)

plt.xlabel('BMIç‰¹å¾')
plt.ylabel('ç–¾ç—…è¿›å±•')
plt.title('ä¸åŒé˜¶æ•°å¤šé¡¹å¼å›å½’æ‹Ÿåˆæ›²çº¿')
plt.legend()
plt.grid(True, alpha=0.3)

# å­å›¾2: RÂ²åˆ†æ•°æ¯”è¾ƒ
plt.subplot(2, 2, 2)
plt.plot(degrees, results_df['RÂ²åˆ†æ•°'], 'o-', linewidth=2, markersize=8)
plt.xlabel('å¤šé¡¹å¼é˜¶æ•°')
plt.ylabel('RÂ²åˆ†æ•°')
plt.title('ä¸åŒé˜¶æ•°çš„RÂ²åˆ†æ•°æ¯”è¾ƒ')
plt.grid(True, alpha=0.3)
for i, r2 in enumerate(results_df['RÂ²åˆ†æ•°']):
    plt.annotate(f'{r2:.3f}', (degrees[i], r2), textcoords="offset points", xytext=(0, 10), ha='center')

# å­å›¾3: MSEæ¯”è¾ƒ
plt.subplot(2, 2, 3)
plt.plot(degrees, results_df['å‡æ–¹è¯¯å·®MSE'], 'o-', linewidth=2, markersize=8, color='red')
plt.xlabel('å¤šé¡¹å¼é˜¶æ•°')
plt.ylabel('å‡æ–¹è¯¯å·®MSE')
plt.title('ä¸åŒé˜¶æ•°çš„MSEæ¯”è¾ƒ')
plt.grid(True, alpha=0.3)
for i, mse in enumerate(results_df['å‡æ–¹è¯¯å·®MSE']):
    plt.annotate(f'{mse:.1f}', (degrees[i], mse), textcoords="offset points", xytext=(0, 10), ha='center')

# å­å›¾4: æœ€ä½³æ¨¡å‹çš„é¢„æµ‹ vs å®é™…å€¼
plt.subplot(2, 2, 4)
best_pred = predictions[best_degree]
plt.scatter(y_test, best_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)
plt.xlabel('å®é™…å€¼')
plt.ylabel('é¢„æµ‹å€¼')
plt.title(f'æœ€ä½³æ¨¡å‹(é˜¶æ•°{best_degree})é¢„æµ‹ vs å®é™…å€¼')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 7. åˆ†æè¿‡æ‹Ÿåˆç°è±¡
print("\n" + "=" * 60)
print("è¿‡æ‹Ÿåˆåˆ†æ")
print("=" * 60)
print("éšç€å¤šé¡¹å¼é˜¶æ•°å¢åŠ ï¼Œæ¨¡å‹å¯èƒ½ä¼šå‡ºç°è¿‡æ‹Ÿåˆï¼š")
print("- ä½é˜¶(1-2): å¯èƒ½æ¬ æ‹Ÿåˆï¼Œæ— æ³•æ•æ‰å¤æ‚å…³ç³»")
print("- ä¸­é˜¶(3): é€šå¸¸æ˜¯æœ€ä½³å¹³è¡¡ç‚¹")
print("- é«˜é˜¶(4-5): å¯èƒ½è¿‡æ‹Ÿåˆï¼Œåœ¨è®­ç»ƒé›†è¡¨ç°å¥½ä½†æµ‹è¯•é›†å·®")

# è®¡ç®—è®­ç»ƒé›†ä¸Šçš„è¡¨ç°è¿›è¡Œæ¯”è¾ƒ
print("\nè®­ç»ƒé›†ä¸æµ‹è¯•é›†æ€§èƒ½å¯¹æ¯”:")
for degree in degrees:
    poly = PolynomialFeatures(degree=degree, include_bias=False)
    X_train_poly = poly.fit_transform(X_train)
    X_test_poly = poly.transform(X_test)

    model = LinearRegression()
    model.fit(X_train_poly, y_train)

    train_r2 = r2_score(y_train, model.predict(X_train_poly))
    test_r2 = r2_score(y_test, model.predict(X_test_poly))

    print(f"é˜¶æ•° {degree}: è®­ç»ƒé›†RÂ² = {train_r2:.4f}, æµ‹è¯•é›†RÂ² = {test_r2:.4f}, å·®è· = {train_r2 - test_r2:.4f}")